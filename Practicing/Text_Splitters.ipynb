{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Ananconda\\envs\\lc_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.document_loaders import YoutubeLoader, YoutubeAudioLoader\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import (RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter,\n",
    "                                      CharacterTextSplitter,TokenTextSplitter)\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '75uBcITe0gU', 'title': '6 Langchain Document Loaders to Master (Beginner Friendly)', 'description': 'Unknown', 'view_count': 3294, 'thumbnail_url': 'https://i.ytimg.com/vi/75uBcITe0gU/hq720.jpg', 'publish_date': '2024-02-15 00:00:00', 'length': 1280, 'author': 'Ryan & Matt Data Science'}, page_content=\"a document is a piece of text and Associated metadata for example a text file CSV YouTube video web page file directory or even a PDF and see we can use something called a document loader to upload these documents to utilize them within our large language models and why I gave all those examples I'm going to be showing you guys how to load each of these specific types of documents in this video with the help of some basic python code if you're brand new here to this YouTube channel I am building out a Series this year based around Lang chain large language models and open AI API now you don't need a ton of background information to understand all the code that is going on this video but if you want to go over some of the basics I have the playlist linked on my Channel with that being said I'm going to be coding all this in Google collab feel free to use whatever code editor that you would like and let's start coding all right so my Google collab notebook let's get going uh what we're going to have to do is actually pip install quite a lot of things so pip install we're going to put our YouTube transcript API in here and that's going to be a fun video in the future but I'll show you guys how we can uh load in our YouTube videos then pip install unstructured okay then up next pip install Pi PDF and then P install Lan chain I think that's the last one I'll just look at my source code yeah so I'm going to run these few lines real quick it'll probably take a minute or two and then we'll Flash Forward once that's done all right so let's start off with doing a normal text document so what we're going to do is from Lang chain Community then we're going to say document loaders which you can find most of this information from so I'm pretty much following the tutorials that are posted on there but tweaking it up a little bit for these videos um so here we go from Lang chain Community document loaders Import in text loader we'll run that over here and what I'm going to do is I'm going to grab in some music lyrics so one of my favorite metal bands is a band called opth I just randomly searched opth lyrics they had this website Dark lyrics sounds kind of spooky some of the opth songs are um but I just went over here and essentially grabbed lyrics to a song threw it into a text file so and I grabbed I believe I grabbed Blackwater perk which is one of my favorite albums of all time regardless uh so let me load that up over here so in Google collab you can just click this folder over here and then you can drag in what you want so let me just drag this in really quick and then it gives you this warning or runtime files will be deleted when this runtime is terminated so anytime you rerun this you'll have to re-upload your files over here it's not a a big deal but it can be a little bit annoying sometimes a video like this where we have a lot of different file formats it's a little annoying but not a big deal again all right so that's in there so all we have to do now is say loader equals text loader like this and then put the file that you want in here now I'm going to bring an op. text like that so run that and we have our opth file in here now the other lines of code again this is a pretty basic tutorial but we can just do doc equals our loader. load like this okay now we have our Doc in here and just to show you what this looks like you can just put dock over here and here we go we have the lyrics for opth song and it's broken down by each line too so just a few lines and we loaded in our text document and uh if you print this out at least in Google collab it all prints out essentially in one line so that's why I kind of just showed doc like that that way you can see it all and at the very end metadata source and then just says opth do text great now let's take a look at how we can bring in a CSV document so I already prepped the CSV document it's it's not perfect by any means but it's for the tutorial so I'm grabbing some past ultra marathon results so ver Beach Ultra my last 50 mile that I ran which one the toughest races yet but they have results on here so I just grabbed those specific results um 2023 right we go over here to the 50 mile and I feel pretty badly at this race but I was getting back into Ultras again and here we go so let's bring in that CSV so what I can do is say from Lang chain community. documents _ loaders CSV loader import CSV loader and like you don't need to put the results in you could literally just grab whatever CSV you want or even already have on your computer and just throw that in so again we'll uh grab this CSV really quick and um throw that over here and let's grab that so now what we're going to do is loader equals CSV loader then put our file path in here equals and then what I like to do is kind of shortcut sometimes is just go over here and just say copy path and then you don't need this slash content in here for Google collab to understand what's going on you a loader in here and then again uh let's set up our data so data equals loader. load like this and that and then if we wanted to print data again I'm just going to print it out data like that and we have our data that's been printed out over here right so ranking names different things like that all across the way uh but there's a few parameters that you could actually just throw in with the CSV document loader so I just want to show you a few of those really quick if it does interest you if not feel free to skip ahead um but I'll just copy the same thing over here again so so loader equals CSV loader file path again perfectly fine as it is right now you can also set up a source column so Source column argument this is what it says on the in the link chain docs it says use the source column argument to specify a source for the document created from HL otherwise the file path will be used as the source for all documents created from the CSV file so you can do that you could also put in some arguments so just to show you how this kind of works we can say Source call equals and let's just say you put your place like the ranking in a specific race right and then we can set up our CSV args so CSV args like this open that up in here first thing you can do is you can set your specific delimiter so delimiter now this CSV that I use is just a comma that splits it so that's pretty basic over there uh another thing that you can can do is set up your field names the field names and then I'm not going to type all these out but I'm just going to copy and paste this what I already had and essentially just put all those different fields in there and you should be good to go try to see really quick why I have an error over here was not closed I close it let's see I forget a comma loader equal CSV loader file path Source column Place CSV args where is my weird either I'm blind or I don't see it I'm just G to copy over my code oh I didn't put the equals sign that makes a lot of sense make sure you put equal sign there and uh boom there we go same thing data equals loader. load right and then if we want to print our data out here we go so page content you'll see first name last name everything like that we'll keep going through State metadata and then we have our source over here and this time for the source it changed into place and it says row Z where as above if we go over here to our source you can see Source 2023 v50 CSV row zero right so feel free to change this as you want add in parameters but all right so now what we're going to do is take a look specifically at a directory loader so what we can do is from L chain Community like this once again document loaders we're going to import in our directory load and what's cool directory loader is you can Import in multiple files at a time so directory loader like that and um you will have to specify what type of format that is but let's go through this uh so let's start off with our text document so we'll do loader equals directory loader like that uh first parameter over here you have to see where your directory is in Google collab it's just going to be pretty much this right U blank no space on here single quotes then we're going to put Globe like this say equals and um we're going to put on this side I things star star and then put your file format so I'm going to put txt we're going to load our text document first and then you have an option also to put if you want to use multi-threading so use multithreading I'm going just going to put it equal to true because technically it's not using my computer it's using um what Google CL uses in the back so we'll run that over here awesome and then what we can do is set docs equal to loader. load like this and run that super fast and you can just put over here length of the docs and we should get one back and we get one awesome now let's take a look at a CSV file so our CSV file is going to be this Viro but what I will say with Google collab we have sample data we have one two three four so some of these might get picked up so it'll either be one of those so let's change this up the CSV over here and we'll rerun this we'll rerun that looks like we are getting two errors loading file the emus test and train wonder if it's going to populate these other two see and then if we go to link docs we should get three this time if there worked properly and we did so if you want to see also what this looks like we can just go over here docks and uh yeah it's uh it's going to take up a lot of the screen so I am just gonna pretend I didn't type that out and we're just going to delete that and keep moving forward so all right so we're going to look at YouTube now just real quick though I did have to install itbe so make sure you pip install that before you start coding otherwise you are going to get an error so I do apologize for not putting that in the beginning uh YouTube's honestly pretty easy to do so what we're going to start off with is from linkchain Community once again. document loaders you're going to get tired of this by the end of the video but Import in our YouTube loader and then and just run that and am I getting an error probably because I had a typo capital T no capital T I'm so used to putting a capital T that should be fixed because I'm pretty sure YouTube has a capital T all right not to go on a tangent or anything like that um all we're going to set this up is loader equals YouTube no Capital YouTube loader from YouTube url then you want to grab in the link to your video um I'm just going to grab in this one right over here so your 9in nails fan awesome if not whatever uh you're missing off on some good music but we'll throw that in over here for our YouTube YouTube url then what I'm going to do next is we're going to add in video info so add video info we can set that equal to true and what's pretty cool and I I'll cover this in another video got to make a capital there um we'll cover this in another video but essentially we can do is set up transcripts so you can also convert your videos to another language so you can just say like language equals and first put the language at the videos in right and then you want to translate it you can do that also I don't need to put the language in Translation here because I believe it's English by default but you can put that in here if you want to but just to show you guys some of the other parameters and um you just want to set up your loader like that I'm not going to load in the YouTube video but essentially that's what you would have to do we'll cover this in another video I promise you and it'll be a pretty fun project um let's go into our HTML loader now and there's actually two different HTML loaders out there so um use which one you want I'm just going to go over those really quick so you can see HTML we have an unstructured and then we have one that also uses beautiful soup I'm just going to use the one that uses beautiful soup for this video These are both kind of similar uh the other differences right so it says beautiful soup we can use load over here this will distract the text from HTML into a page content a page title into the metadata this cover all load HTML documents into a document format that we can use Downstream so just use beautiful soup because I've used it for scraping before which would be kind of fun I could make some scraping videos in the future but uh not to go on a tangent or anything like that from L chain community that document loaders loaders like that import the S HTML loader like that onun that over here and then we're going have to put loader equals we'll put this b bs HTML loader and then you're going to have to put an HTML file in here um I'm just going to grab the HTML file from my own website so not my coding website which I still need to do that but my uh sports card website so breakout cards. HML and just to show you guys like I haven't worked on this a lot recently but I definitely need to in the future but this is my website for sports cards so up coping card shows I stopped that a long time ago that you can tell like last time I've updated this website it's been quite a while but regardless as my website on here been focusing a lot more on the coding side um but I have my breakout cards HTML so we can just rename this file if we wanted to or just copy it right copy that throw it in here oh and I forgot to show you all you want to save website HTML you just right click over here you can click save as and um you can just do webpage. HTML obviously don't have this name over here but like Lang chain. HTML if you really want to I'm not going to save it but uh that's what you could specifically do all right uh back over here just showed you how you can download the HTML we have our loader just run the loader and then like the rest of this video data equals loader. [Music] load and um be a lot of data so I'm just show you data again all populates over here don't really need it so delete because I'd rather have this a little bit cleaner but that's how you would do that and lastly let's take a look at a PDF so we're going to go from Lane chain we need document loaders we'll just copy this one and this time what we're going to do is put over here Pi PDF loader like that run that over here loader equals Pi PDF loader we'll grab that throw it over here now you need your PDF file um we'll just throw this in over here so I collect a lot of foreign issues this is kind of like a magazine from overseas Card World so just show you guys what this looks like really quick you can just tell how much I'm uner in this video but like we're talking about foreign nons sports cards so and some prices and stuff like that regardless right just my first first PDF I found I using it for this video okay so throw that in over here or just copy that path paste that over here delete that so now we have our loader like that then we can just say like Pages this time or data use whatever want right I'll but I'm just going to say loader. load and splits like that and what's cool is we can actually grab specific Pages now from the PDF and now if you want to see a specific page you just go over here to pages and just put a number in here so let's say like we wanted to see the first page which is Page zero populates that right Card World March April 2023 low resolution PDF we go back over here right page zero and um can change this as you want right so go back if we put like Pages gra 11 and then put that over here you can see a page 11 is there's a lot of pages in this PDF so I'm not going to go through that all but you kind of understand how the basics work so just to kind of like rate what we covered in this video essentially go to Lang chain Community document loaders or whatever document that you want to load up and showed you how you can do most of these out here there's also like Json a few other file formats I did not specifically cover mark down as well so import that in make sure you pip install any packages that you need for that specific loader then throw in the file over here or you could use your directory and just grab that just depends on your file format on that side of things and each uh docum is a little bit different but for the PDF one we can grab Pages other ones you can just grab everything at hey you made it to the end of this video well congrats you learned about document loaders I'm going to be expanding on these in future videos as well as a project so make sure to stay tuned for that by subscribing to the channel it's 100% for free and it also shows YouTube that people enjoy the videos that I am developing now if you want to check out my full playlist of AI videos I have them right over here\")]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_url = 'https://youtu.be/75uBcITe0gU?si=Ggfa8c8uMb6P-dfR'\n",
    "\n",
    "loader = YoutubeLoader.from_youtube_url(video_url, add_video_info=True)\n",
    "text = loader.load()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '75uBcITe0gU',\n",
       " 'title': '6 Langchain Document Loaders to Master (Beginner Friendly)',\n",
       " 'description': 'Unknown',\n",
       " 'view_count': 3294,\n",
       " 'thumbnail_url': 'https://i.ytimg.com/vi/75uBcITe0gU/hq720.jpg',\n",
       " 'publish_date': '2024-02-15 00:00:00',\n",
       " 'length': 1280,\n",
       " 'author': 'Ryan & Matt Data Science'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "chunks_recursive = recursive_text_splitter.split_documents(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Content : \n",
      " a document is a piece of text and Associated metadata for example a text file CSV YouTube video web page file directory or even a PDF and see we can use something called a document loader to upload these documents to utilize them within our large language models and why I gave all those examples I'm going to be showing you guys how to load each of these specific types of documents in this video with the help of some basic python code if you're brand new here to this YouTube channel I am building\n",
      "Page Content : \n",
      " the help of some basic python code if you're brand new here to this YouTube channel I am building out a Series this year based around Lang chain large language models and open AI API now you don't need a ton of background information to understand all the code that is going on this video but if you want to go over some of the basics I have the playlist linked on my Channel with that being said I'm going to be coding all this in Google collab feel free to use whatever code editor that you would\n",
      "Page Content : \n",
      " going to be coding all this in Google collab feel free to use whatever code editor that you would like and let's start coding all right so my Google collab notebook let's get going uh what we're going to have to do is actually pip install quite a lot of things so pip install we're going to put our YouTube transcript API in here and that's going to be a fun video in the future but I'll show you guys how we can uh load in our YouTube videos then pip install unstructured okay then up next pip\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks_recursive[:3]:\n",
    "    print('Page Content : \\n', chunk.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page content : \n",
      " page_content='a document is a piece of text and Associated metadata for example a text file CSV YouTube video web page file directory or even a PDF and see we can use something called a document loader to upload these documents to utilize them within our large language models and why I gave all those examples I'm going to be showing you guys how to load each of these specific types of documents in this video with the help of some basic python code if you're brand new here to this YouTube channel I am building out a Series this year based around Lang chain large language models and open AI API now you don't need a ton of background information to understand all the code that is going on this video but if you want to go over some of the basics I have the playlist linked on my Channel with that being said I'm going to be coding all this in Google collab feel free to use whatever code editor that you would like and let's start coding all right so my Google collab notebook let's get going uh what we're going to have to do is actually pip install quite a lot of things so pip install we're going to put our YouTube transcript API in here and that's going to be a fun video in the future but I'll show you guys how we can uh load in our YouTube videos then pip install unstructured okay then up next pip install Pi PDF and then P install Lan chain I think that's the last one I'll just look at my source code yeah so I'm going to run these few lines real quick it'll probably take a minute or two and then we'll Flash Forward once that's done all right so let's start off with doing a normal text document so what we're going to do is from Lang chain Community then we're going to say document loaders which you can find most of this information from so I'm pretty much following the tutorials that are posted on there but tweaking it up a little bit for these videos um so here we go from Lang chain Community document loaders Import in text loader we'll run that over here and what I'm going to do is I'm going to grab in some music lyrics so one of my favorite metal bands is a band called opth I just randomly searched opth lyrics they had this website Dark lyrics sounds kind of spooky some of the opth songs are um but I just went over here and essentially grabbed lyrics to a song threw it into a text file so and I grabbed I believe I grabbed Blackwater perk which is one of my favorite albums of all time regardless uh so let me load that up over here so in Google collab you can just click this folder over here and then you can drag in what you want so let me just drag this in really quick and then it gives you this warning or runtime files will be deleted when this runtime is terminated so anytime you rerun this you'll have to re-upload your files over here it's not a a big deal but it can be a little bit annoying sometimes a video like this where we have a lot of different file formats it's a little annoying but not a big deal again all right so that's in there so all we have to do now is say loader equals text loader like this and then put the file that you want in here now I'm going to bring an op. text like that so run that and we have our opth file in here now the other lines of code again this is a pretty basic tutorial but we can just do doc equals our loader. load like this okay now we have our Doc in here and just to show you what this looks like you can just put dock over here and here we go we have the lyrics for opth song and it's broken down by each line too so just a few lines and we loaded in our text document and uh if you print this out at least in Google collab it all prints out essentially in one line so that's why I kind of just showed doc like that that way you can see it all and at the very end metadata source and then just says opth do text great now let's take a look at how we can bring in a CSV document so I already prepped the CSV document it's it's not perfect by any means but it's for the tutorial so I'm grabbing some past ultra marathon results so ver Beach Ultra my last 50 mile that I ran which one the toughest races yet but they have results on here so I just grabbed those specific results um 2023 right we go over here to the 50 mile and I feel pretty badly at this race but I was getting back into Ultras again and here we go so let's bring in that CSV so what I can do is say from Lang chain community. documents _ loaders CSV loader import CSV loader and like you don't need to put the results in you could literally just grab whatever CSV you want or even already have on your computer and just throw that in so again we'll uh grab this CSV really quick and um throw that over here and let's grab that so now what we're going to do is loader equals CSV loader then put our file path in here equals and then what I like to do is kind of shortcut sometimes is just go over here and just say copy path and then you don't need this slash content in here for Google collab to understand what's going on you a loader in here and then again uh let's set up our data so data equals loader. load like this and that and then if we wanted to print data again I'm just going to print it out data like that and we have our data that's been printed out over here right so ranking names different things like that all across the way uh but there's a few parameters that you could actually just throw in with the CSV document loader so I just want to show you a few of those really quick if it does interest you if not feel free to skip ahead um but I'll just copy the same thing over here again so so loader equals CSV loader file path again perfectly fine as it is right now you can also set up a source column so Source column argument this is what it says on the in the link chain docs it says use the source column argument to specify a source for the document created from HL otherwise the file path will be used as the source for all documents created from the CSV file so you can do that you could also put in some arguments so just to show you how this kind of works we can say Source call equals and let's just say you put your place like the ranking in a specific race right and then we can set up our CSV args so CSV args like this open that up in here first thing you can do is you can set your specific delimiter so delimiter now this CSV that I use is just a comma that splits it so that's pretty basic over there uh another thing that you can can do is set up your field names the field names and then I'm not going to type all these out but I'm just going to copy and paste this what I already had and essentially just put all those different fields in there and you should be good to go try to see really quick why I have an error over here was not closed I close it let's see I forget a comma loader equal CSV loader file path Source column Place CSV args where is my weird either I'm blind or I don't see it I'm just G to copy over my code oh I didn't put the equals sign that makes a lot of sense make sure you put equal sign there and uh boom there we go same thing data equals loader. load right and then if we want to print our data out here we go so page content you'll see first name last name everything like that we'll keep going through State metadata and then we have our source over here and this time for the source it changed into place and it says row Z where as above if we go over here to our source you can see Source 2023 v50 CSV row zero right so feel free to change this as you want add in parameters but all right so now what we're going to do is take a look specifically at a directory loader so what we can do is from L chain Community like this once again document loaders we're going to import in our directory load and what's cool directory loader is you can Import in multiple files at a time so directory loader like that and um you will have to specify what type of format that is but let's go through this uh so let's start off with our text document so we'll do loader equals directory loader like that uh first parameter over here you have to see where your directory is in Google collab it's just going to be pretty much this right U blank no space on here single quotes then we're going to put Globe like this say equals and um we're going to put on this side I things star star and then put your file format so I'm going to put txt we're going to load our text document first and then you have an option also to put if you want to use multi-threading so use multithreading I'm going just going to put it equal to true because technically it's not using my computer it's using um what Google CL uses in the back so we'll run that over here awesome and then what we can do is set docs equal to loader. load like this and run that super fast and you can just put over here length of the docs and we should get one back and we get one awesome now let's take a look at a CSV file so our CSV file is going to be this Viro but what I will say with Google collab we have sample data we have one two three four so some of these might get picked up so it'll either be one of those so let's change this up the CSV over here and we'll rerun this we'll rerun that looks like we are getting two errors loading file the emus test and train wonder if it's going to populate these other two see and then if we go to link docs we should get three this time if there worked properly and we did so if you want to see also what this looks like we can just go over here docks and uh yeah it's uh it's going to take up a lot of the screen so I am just gonna pretend I didn't type that out and we're just going to delete that and keep moving forward so all right so we're going to look at YouTube now just real quick though I did have to install itbe so make sure you pip install that before you start coding otherwise you are going to get an error so I do apologize for not putting that in the beginning uh YouTube's honestly pretty easy to do so what we're going to start off with is from linkchain Community once again. document loaders you're going to get tired of this by the end of the video but Import in our YouTube loader and then and just run that and am I getting an error probably because I had a typo capital T no capital T I'm so used to putting a capital T that should be fixed because I'm pretty sure YouTube has a capital T all right not to go on a tangent or anything like that um all we're going to set this up is loader equals YouTube no Capital YouTube loader from YouTube url then you want to grab in the link to your video um I'm just going to grab in this one right over here so your 9in nails fan awesome if not whatever uh you're missing off on some good music but we'll throw that in over here for our YouTube YouTube url then what I'm going to do next is we're going to add in video info so add video info we can set that equal to true and what's pretty cool and I I'll cover this in another video got to make a capital there um we'll cover this in another video but essentially we can do is set up transcripts so you can also convert your videos to another language so you can just say like language equals and first put the language at the videos in right and then you want to translate it you can do that also I don't need to put the language in Translation here because I believe it's English by default but you can put that in here if you want to but just to show you guys some of the other parameters and um you just want to set up your loader like that I'm not going to load in the YouTube video but essentially that's what you would have to do we'll cover this in another video I promise you and it'll be a pretty fun project um let's go into our HTML loader now and there's actually two different HTML loaders out there so um use which one you want I'm just going to go over those really quick so you can see HTML we have an unstructured and then we have one that also uses beautiful soup I'm just going to use the one that uses beautiful soup for this video These are both kind of similar uh the other differences right so it says beautiful soup we can use load over here this will distract the text from HTML into a page content a page title into the metadata this cover all load HTML documents into a document format that we can use Downstream so just use beautiful soup because I've used it for scraping before which would be kind of fun I could make some scraping videos in the future but uh not to go on a tangent or anything like that from L chain community that document loaders loaders like that import the S HTML loader like that onun that over here and then we're going have to put loader equals we'll put this b bs HTML loader and then you're going to have to put an HTML file in here um I'm just going to grab the HTML file from my own website so not my coding website which I still need to do that but my uh sports card website so breakout cards. HML and just to show you guys like I haven't worked on this a lot recently but I definitely need to in the future but this is my website for sports cards so up coping card shows I stopped that a long time ago that you can tell like last time I've updated this website it's been quite a while but regardless as my website on here been focusing a lot more on the coding side um but I have my breakout cards HTML so we can just rename this file if we wanted to or just copy it right copy that throw it in here oh and I forgot to show you all you want to save website HTML you just right click over here you can click save as and um you can just do webpage. HTML obviously don't have this name over here but like Lang chain. HTML if you really want to I'm not going to save it but uh that's what you could specifically do all right uh back over here just showed you how you can download the HTML we have our loader just run the loader and then like the rest of this video data equals loader. [Music] load and um be a lot of data so I'm just show you data again all populates over here don't really need it so delete because I'd rather have this a little bit cleaner but that's how you would do that and lastly let's take a look at a PDF so we're going to go from Lane chain we need document loaders we'll just copy this one and this time what we're going to do is put over here Pi PDF loader like that run that over here loader equals Pi PDF loader we'll grab that throw it over here now you need your PDF file um we'll just throw this in over here so I collect a lot of foreign issues this is kind of like a magazine from overseas Card World so just show you guys what this looks like really quick you can just tell how much I'm uner in this video but like we're talking about foreign nons sports cards so and some prices and stuff like that regardless right just my first first PDF I found I using it for this video okay so throw that in over here or just copy that path paste that over here delete that so now we have our loader like that then we can just say like Pages this time or data use whatever want right I'll but I'm just going to say loader. load and splits like that and what's cool is we can actually grab specific Pages now from the PDF and now if you want to see a specific page you just go over here to pages and just put a number in here so let's say like we wanted to see the first page which is Page zero populates that right Card World March April 2023 low resolution PDF we go back over here right page zero and um can change this as you want right so go back if we put like Pages gra 11 and then put that over here you can see a page 11 is there's a lot of pages in this PDF so I'm not going to go through that all but you kind of understand how the basics work so just to kind of like rate what we covered in this video essentially go to Lang chain Community document loaders or whatever document that you want to load up and showed you how you can do most of these out here there's also like Json a few other file formats I did not specifically cover mark down as well so import that in make sure you pip install any packages that you need for that specific loader then throw in the file over here or you could use your directory and just grab that just depends on your file format on that side of things and each uh docum is a little bit different but for the PDF one we can grab Pages other ones you can just grab everything at hey you made it to the end of this video well congrats you learned about document loaders I'm going to be expanding on these in future videos as well as a project so make sure to stay tuned for that by subscribing to the channel it's 100% for free and it also shows YouTube that people enjoy the videos that I am developing now if you want to check out my full playlist of AI videos I have them right over here' metadata={'source': '75uBcITe0gU', 'title': '6 Langchain Document Loaders to Master (Beginner Friendly)', 'description': 'Unknown', 'view_count': 3294, 'thumbnail_url': 'https://i.ytimg.com/vi/75uBcITe0gU/hq720.jpg', 'publish_date': '2024-02-15 00:00:00', 'length': 1280, 'author': 'Ryan & Matt Data Science'}\n",
      "\n",
      " length : 16749\n"
     ]
    }
   ],
   "source": [
    "character_text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "chunks_character = character_text_splitter.split_documents(text)\n",
    "\n",
    "for chunk in chunks_character[:2]:\n",
    "    print('page content : \\n', chunk)\n",
    "\n",
    "print('\\n length :', len(chunks_character[0].page_content)) # this happens because there was no next paragraph there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SentenceTransformersTokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page content: \n",
      " a document is a piece of text and associated metadata for example a text file csv youtube video web page file directory or even a pdf and see we can use something called a document loader to upload these documents to utilize them within our large language models and why i gave all those examples i'm going to be showing you guys how to load each of these specific types of documents in this video with the help of some basic python code if you're brand new here to this youtube channel i am building out a series this year based around lang chain large language models and open ai api now you don't need a ton of background information to understand all the code that is going on this video but if you want to go over some of the basics i have the playlist linked on my channel with that being said i'm going to be coding all this in google collab feel free to use whatever code editor that you would like and let's start coding all right so my google collab notebook let's get going uh what we're going to have to do is actually pip install quite a lot of things so pip install we're going to put our youtube transcript api in here and that's going to be a fun video in the future but i'll show you guys how we can uh load in our youtube videos then pip install unstructured okay then up next pip install pi pdf and then p install lan chain i think that's the last one i'll just look at my source code yeah so i'm going to run these few lines real quick it'll probably take a minute or two and then we'll flash forward once that's done all right so let's start off with doing a normal text document so what we're going to do is from lang chain community then we're going to say document loaders which you can find most of\n",
      "\n",
      " length : 1723\n",
      "page content: \n",
      " flash forward once that's done all right so let's start off with doing a normal text document so what we're going to do is from lang chain community then we're going to say document loaders which you can find most of this information from so i'm pretty much following the tutorials that are posted on there but tweaking it up a little bit for these videos um so here we go from lang chain community document loaders import in text loader we'll run that over here and what i'm going to do is i'm going to grab in some music lyrics so one of my favorite metal bands is a band called opth i just randomly searched opth lyrics they had this website dark lyrics sounds kind of spooky some of the opth songs are um but i just went over here and essentially grabbed lyrics to a song threw it into a text file so and i grabbed i believe i grabbed blackwater perk which is one of my favorite albums of all time regardless uh so let me load that up over here so in google collab you can just click this folder over here and then you can drag in what you want so let me just drag this in really quick and then it gives you this warning or runtime files will be deleted when this runtime is terminated so anytime you rerun this you'll have to re - upload your files over here it's not a a big deal but it can be a little bit annoying sometimes a video like this where we have a lot of different file formats it's a little annoying but not a big deal again all right so that's in there so all we have to do now is say loader equals text loader like this and then put the file that you want in here now i'm going to bring an op. text like that so run that and we have our opth file\n",
      "\n",
      " length : 1667\n",
      "page content: \n",
      " so all we have to do now is say loader equals text loader like this and then put the file that you want in here now i'm going to bring an op. text like that so run that and we have our opth file in here now the other lines of code again this is a pretty basic tutorial but we can just do doc equals our loader. load like this okay now we have our doc in here and just to show you what this looks like you can just put dock over here and here we go we have the lyrics for opth song and it's broken down by each line too so just a few lines and we loaded in our text document and uh if you print this out at least in google collab it all prints out essentially in one line so that's why i kind of just showed doc like that that way you can see it all and at the very end metadata source and then just says opth do text great now let's take a look at how we can bring in a csv document so i already prepped the csv document it's it's not perfect by any means but it's for the tutorial so i'm grabbing some past ultra marathon results so ver beach ultra my last 50 mile that i ran which one the toughest races yet but they have results on here so i just grabbed those specific results um 2023 right we go over here to the 50 mile and i feel pretty badly at this race but i was getting back into ultras again and here we go so let's bring in that csv so what i can do is say from lang chain community. documents _ loaders csv loader import csv loader and like you don't need to put the results in you could literally just grab whatever csv you want or even already have on your computer and just throw that in so\n",
      "\n",
      " length : 1607\n"
     ]
    }
   ],
   "source": [
    "sentence_character_splitter = SentenceTransformersTokenTextSplitter(chunk_size=200, chunk_overlap=50)\n",
    "chunks_sentence = sentence_character_splitter.split_documents(text)\n",
    "\n",
    "for chunk in chunks_sentence[:3]:\n",
    "    print('page content: \\n', chunk.page_content) # same here is that it tries to find the sentence ending but it didn't do that much better \n",
    "    print('\\n length :', len(chunk.page_content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page content: \n",
      " a document is a piece of text and Associated metadata for example a text file CSV YouTube video web page file directory or even a PDF and see we can use something called a document loader to upload these documents to utilize them within our large language models and why\n",
      "length : 270\n",
      "\n",
      "page content: \n",
      "  to utilize them within our large language models and why I gave all those examples I'm going to be showing you guys how to load each of these specific types of documents in this video with the help of some basic python code if you're brand new here\n",
      "length : 249\n",
      "\n",
      "page content: \n",
      "  some basic python code if you're brand new here to this YouTube channel I am building out a Series this year based around Lang chain large language models and open AI API now you don't need a ton of background information to understand all the code that is\n",
      "length : 257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "token_splitter = TokenTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "chunk_token= token_splitter.split_documents(text)\n",
    "\n",
    "for chunk in chunk_token[:3]:\n",
    "    print('page content: \\n', chunk.page_content) \n",
    "    print(f'length : {len(chunk.page_content)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SemanticChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\Users\\HP\\Desktop\\langchain-crash-course\\Practicing\\Books\\The Art of Being ALONE Solitude Is My HOME, Loneliness Was My Cage.pdf'\n",
    "pdf_loader = PyMuPDFLoader(file_path=file_path)\n",
    "pdf_text = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sementic_splitter = SemanticChunker(GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\"), \n",
    "                                    breakpoint_threshold_type = 'percentile' )\n",
    "sementic_chunk = sementic_splitter.split_documents(pdf_text) # split the sentence on the base of .?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'C:\\\\Users\\\\HP\\\\Desktop\\\\langchain-crash-course\\\\Practicing\\\\Books\\\\The Art of Being ALONE Solitude Is My HOME, Loneliness Was My Cage.pdf',\n",
       " 'file_path': 'C:\\\\Users\\\\HP\\\\Desktop\\\\langchain-crash-course\\\\Practicing\\\\Books\\\\The Art of Being ALONE Solitude Is My HOME, Loneliness Was My Cage.pdf',\n",
       " 'page': 0,\n",
       " 'total_pages': 99,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': 'The Art of Being ALONE: Solitude Is My HOME, Loneliness Was My Cage',\n",
       " 'author': 'Renuka Gavrani',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'creator': 'calibre 6.28.1',\n",
       " 'producer': 'calibre 6.28.1',\n",
       " 'creationDate': \"D:20231115105259+00'00'\",\n",
       " 'modDate': \"D:20231115105259+00'00'\",\n",
       " 'trapped': ''}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sementic_chunk[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sementic_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page content: \n",
      " page_content='the crowds. While Stieglitz, her husband, was a social\n",
      "butterfly, OKeeffe preferred being alone. She always said\n",
      "There is a kind of freedom in being alone.\n",
      "Finally, in 1929, after much deliberation, she left for New\n",
      "Mexico for the very first time. This became the first of her\n",
      "many extended trips in the desert, where she spent months\n",
      "wandering alone, living in tents, with nothing but her art\n",
      "supplies for the company. In 1934 OKeeffe bought a piece of land on a ghost ranch\n",
      "and permanently moved to the desert. Here she spent four\n",
      "years restoring the ranch and setting up her solitary abode. Her minimalist house with a view of the Cerro Paranal\n",
      "mountains became her own little haven, where she lived up\n",
      "to almost a hundred years deliciously alone, in blissful\n",
      "solitude, making art till her body allowed her. Her art and the inspiration behind it were simple as she\n",
      "used to say, \"I had to create an equivalent for what I\n",
      "felt about what I was looking at  not copy it.\"\n",
      "Georgia OKeeffe is not the first nor the only artist who\n",
      "found inspiration in solitude. History, if you flip the pages, is\n",
      "filled with examples of legendary artists, warriors, and\n",
      "writers who found their hearts speaking to them directly\n",
      "when they spent time with themselves. Much like Georgia,\n",
      "Nikola Tesla preferred solitude and went on to say, The\n",
      "mind is sharper and keener in seclusion and uninterrupted\n",
      "solitude. No big laboratory is needed in which to think.' metadata={'source': 'C:\\\\Users\\\\HP\\\\Desktop\\\\langchain-crash-course\\\\Practicing\\\\Books\\\\The Art of Being ALONE Solitude Is My HOME, Loneliness Was My Cage.pdf', 'file_path': 'C:\\\\Users\\\\HP\\\\Desktop\\\\langchain-crash-course\\\\Practicing\\\\Books\\\\The Art of Being ALONE Solitude Is My HOME, Loneliness Was My Cage.pdf', 'page': 46, 'total_pages': 99, 'format': 'PDF 1.4', 'title': 'The Art of Being ALONE: Solitude Is My HOME, Loneliness Was My Cage', 'author': 'Renuka Gavrani', 'subject': '', 'keywords': '', 'creator': 'calibre 6.28.1', 'producer': 'calibre 6.28.1', 'creationDate': \"D:20231115105259+00'00'\", 'modDate': \"D:20231115105259+00'00'\", 'trapped': ''}\n",
      "length : 1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('page content: \\n', sementic_chunk[100]) \n",
    "print(f'length : {len(sementic_chunk[100].page_content)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Qdrant vector store\n",
    "\n",
    "**to do the chunking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
