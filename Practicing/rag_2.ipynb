{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\HP\\\\Desktop\\\\langchain-crash-course\\\\Practicing'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the directiory\n",
    "# current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = os.path.join(current_dir , \"Books\")\n",
    "db_folder = os.path.join(current_dir , \"db\")\n",
    "db_file_path = os.path.join(db_folder , \"chroma_metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1697, which is longer than the specified 1000\n",
      "Created a chunk of size 1384, which is longer than the specified 1000\n",
      "Created a chunk of size 1298, which is longer than the specified 1000\n",
      "Created a chunk of size 1043, which is longer than the specified 1000\n",
      "Created a chunk of size 1339, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(folder_path):\n",
    "    # loading the documents\n",
    "\n",
    "    book_files = [os.path.join(folder_path , i) for i in os.listdir(folder_path) if i.endswith('.pdf')]\n",
    "\n",
    "    documents=[]\n",
    "    for book in book_files:\n",
    "        loader = PyMuPDFLoader(book)\n",
    "        doc_loaded = loader.load() # returns a list\n",
    "\n",
    "        for doc in doc_loaded:\n",
    "            doc.metadata = {'source' : book}\n",
    "            documents.append(doc)\n",
    "    \n",
    "    # getting the chunks\n",
    "\n",
    "    splitter = CharacterTextSplitter(chunk_size=1000 , chunk_overlap=200)\n",
    "    docs = splitter.split_documents(documents) # here instead of using split_text we will use split_documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/text-embedding-004\" , google_api_key='AIzaSyA77gUQw_Fzk2L4hJx_6fzQOSZipJn_ZTg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(\n",
    "    docs , embeddings , persist_directory=db_file_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'what is First aggremeent'\n",
    "\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 3, \"score_threshold\": 0.1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "THE FIRST AGREEMENT\n",
      "source :  c:\\Users\\HP\\Desktop\\langchain-crash-course\\Practicing\\Books\\The Four Agreements.pdf\n",
      "3\n",
      "THE SECOND AGREEMENT\n",
      "source :  c:\\Users\\HP\\Desktop\\langchain-crash-course\\Practicing\\Books\\The Four Agreements.pdf\n",
      "CONTENTS\n",
      " \n",
      "INTRODUCTION\n",
      "1\n",
      "Domestication and\n",
      "the Dream of the Planet\n",
      "2\n",
      "THE FIRST AGREEMENT\n",
      "Be Impeccable with Your Word\n",
      "3\n",
      "THE SECOND AGREEMENT\n",
      "Don’t Take Anything Personally\n",
      "4\n",
      "THE THIRD AGREEMENT\n",
      "Don’t Make Assumptions\n",
      "5\n",
      "THE FOURTH AGREEMENT\n",
      "Always Do Your Best\n",
      "6\n",
      "THE TOLTEC PATH TO FREEDOM\n",
      "Breaking Old Agreements\n",
      "7\n",
      "source :  c:\\Users\\HP\\Desktop\\langchain-crash-course\\Practicing\\Books\\The Four Agreements.pdf\n"
     ]
    }
   ],
   "source": [
    "for ans in answers:\n",
    "    print(ans.page_content)\n",
    "    print('source : ' , ans.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
